#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

### METADATA | ENV ###

# The metadata store in hbase
kylin.metadata.url=kylin_metadata@hbase

# metadata cache sync retry times
kylin.metadata.sync-retries=3

# Working folder in HDFS, better be qualified absolute path, make sure user has the right permission to this directory
kylin.env.hdfs-working-dir=/kylin

# DEV|QA|PROD. DEV will turn on some dev features, QA and PROD has no difference in terms of functions.
kylin.env=QA

# kylin zk base path
kylin.env.zookeeper-base-path=/kylin

### SERVER | WEB | RESTCLIENT ###

# Kylin server mode, valid value [all, query, job]
kylin.server.mode=all

# List of web servers in use, this enables one web server instance to sync up with other servers.
kylin.server.cluster-servers=localhost:7070

# Display timezone on UI,format like[GMT+N or GMT-N]
kylin.web.timezone=GMT+8

kylin.web.cross-domain-enabled=true

#max connections of one route
kylin.restclient.connection.default-max-per-route=20

#max connections of one rest-client
kylin.restclient.connection.max-total=200


### SOURCE ###

# Hive client, valid value [cli, beeline]
kylin.source.hive.client=cli

# Parameters for beeline client, only necessary if hive client is beeline
#kylin.source.hive.beeline-params=-n root --hiveconf hive.security.authorization.sqlstd.confwhitelist.append='mapreduce.job.*|dfs.*' -u jdbc:hive2://localhost:10000

kylin.source.hive.keep-flat-table=false

# Hive database name for putting the intermediate flat tables
kylin.source.hive.database-for-flat-table=default

# Whether redistribute the intermediate flat table before building
kylin.source.hive.redistribute-flat-table=true


### STORAGE ###

# The storage for final cube file in hbase
kylin.storage.url=hbase

# The prefix of hbase table
kylin.storage.hbase.table-name-prefix=KYLIN_

# Compression codec for htable, valid value [none, snappy, lzo, gzip, lz4]
kylin.storage.hbase.compression-codec=none

# HBase Cluster FileSystem, which serving hbase, format as hdfs://hbase-cluster:8020
# Leave empty if hbase running on same cluster with hive and mapreduce
#kylin.storage.hbase.cluster-fs=

# The cut size for hbase region, in GB.
kylin.storage.hbase.region-cut-gb=5

# The hfile size of GB, smaller hfile leading to the converting hfile MR has more reducers and be faster.
# Set 0 to disable this optimization.
kylin.storage.hbase.hfile-size-gb=2

kylin.storage.hbase.min-region-count=1
kylin.storage.hbase.max-region-count=500

# Optional information for the owner of kylin platform, it can be your team's email
# Currently it will be attached to each kylin's htable attribute
kylin.storage.hbase.owner-tag=whoami@kylin.apache.org

kylin.storage.hbase.coprocessor-mem-gb=3

# By default kylin can spill query's intermediate results to disks when it's consuming too much memory.
# Set it to false if you want query to abort immediately in such condition.
kylin.storage.partition.aggr-spill-enabled=true

# The maximum number of bytes each coprocessor is allowed to scan.
# To allow arbitrary large scan, you can set it to 0.
kylin.storage.partition.max-scan-bytes=3221225472

# The default coprocessor timeout is (hbase.rpc.timeout * 0.9) / 1000 seconds,
# You can set it to a smaller value. 0 means use default.
# kylin.storage.hbase.coprocessor-timeout-seconds=0


### JOB ###

# Max job retry on error, default 0: no retry
kylin.job.retry=0

# Max count of concurrent jobs running
kylin.job.max-concurrent-jobs=10

# The percentage of the sampling, default 100%
kylin.job.sampling-percentage=100

# Whether get job status from resource manager with kerberos authentication
kylin.job.status.with.kerberos=false

# Timeout in seconds
kylin.job.step.timeout=7200

# If true, will send email notification on job complete
#kylin.job.notification-enabled=true
#kylin.job.notification-mail-enable-starttls=true
#kylin.job.notification-mail-host=smtp.office365.com
#kylin.job.notification-mail-port=587
#kylin.job.notification-mail-username=kylin@example.com
#kylin.job.notification-mail-password=mypassword
#kylin.job.notification-mail-sender=kylin@example.com


### ENGINE ###

# Time interval to check hadoop job status
kylin.engine.mr.yarn-check-interval-seconds=10

kylin.engine.mr.reduce-input-mb=500

kylin.engine.mr.max-reducer-number=500

kylin.engine.mr.mapper-input-rows=1000000

# Enable dictionary building in MR reducer
kylin.engine.mr.build-dict-in-reducer=true

# Number of reducers for fetching UHC column distinct values
kylin.engine.mr.uhc-reducer-count=1


### CUBE | DICTIONARY ###

kylin.cube.cuboid-scheduler=org.apache.kylin.cube.cuboid.DefaultCuboidScheduler
kylin.cube.segment-advisor=org.apache.kylin.cube.CubeSegmentAdvisor

# 'auto', 'inmem', 'layer' or 'random' for testing 
kylin.cube.algorithm=layer

# A smaller threshold prefers layer, a larger threshold prefers in-mem
kylin.cube.algorithm.layer-or-inmem-threshold=7

kylin.cube.aggrgroup.max-combination=4096

kylin.snapshot.max-mb=300

kylin.cube.cubeplanner.enabled=false
kylin.cube.cubeplanner.enabled-for-existing-cube=false
kylin.cube.cubeplanner.expansion-threshold=15.0
kylin.cube.cubeplanner.recommend-cache-max-size=200
kylin.cube.cubeplanner.mandatory-rollup-threshold=1000
kylin.cube.cubeplanner.algorithm-threshold-greedy=10
kylin.cube.cubeplanner.algorithm-threshold-genetic=23


### QUERY ###

# Controls the maximum number of bytes a query is allowed to scan storage.
# The default value 0 means no limit.
# The counterpart kylin.storage.partition.max-scan-bytes sets the maximum per coprocessor.
kylin.query.max-scan-bytes=0

kylin.query.cache-enabled=true


### SECURITY ###

# Spring security profile, options: testing, ldap, saml
# with "testing" profile, user can use pre-defined name/pwd like KYLIN/ADMIN to login
kylin.security.profile=testing

# Default roles and admin roles in LDAP, for ldap and saml
kylin.security.acl.default-role=ROLE_ANALYST,ROLE_MODELER
kylin.security.acl.admin-role=ROLE_ADMIN

# LDAP authentication configuration
kylin.security.ldap.connection-server=ldap://ldap_server:389
kylin.security.ldap.connection-username=
kylin.security.ldap.connection-password=

# LDAP user account directory;
kylin.security.ldap.user-search-base=
kylin.security.ldap.user-search-pattern=
kylin.security.ldap.user-group-search-base=

# LDAP service account directory
kylin.security.ldap.service-search-base=
kylin.security.ldap.service-search-pattern=
kylin.security.ldap.service-group-search-base=

## SAML configurations for SSO
# SAML IDP metadata file location
kylin.security.saml.metadata-file=classpath:sso_metadata.xml
kylin.security.saml.metadata-entity-base-url=https://hostname/kylin
kylin.security.saml.context-scheme=https
kylin.security.saml.context-server-name=hostname
kylin.security.saml.context-server-port=443
kylin.security.saml.context-path=/kylin


### SPARK ENGINE CONFIGS ###

# Hadoop conf folder, will export this as "HADOOP_CONF_DIR" to run spark-submit
# This must contain site xmls of core, yarn, hive, and hbase in one folder
#kylin.env.hadoop-conf-dir=/etc/hadoop/conf

# Estimate the RDD partition numbers
kylin.engine.spark.rdd-partition-cut-mb=10

# Minimal partition numbers of rdd
kylin.engine.spark.min-partition=1

# Max partition numbers of rdd
kylin.engine.spark.max-partition=5000

# Spark conf (default is in spark/conf/spark-defaults.conf)
kylin.engine.spark-conf.spark.master=yarn
#kylin.engine.spark-conf.spark.submit.deployMode=cluster
kylin.engine.spark-conf.spark.yarn.queue=default
kylin.engine.spark-conf.spark.executor.memory=1G
kylin.engine.spark-conf.spark.executor.cores=2
kylin.engine.spark-conf.spark.executor.instances=1
kylin.engine.spark-conf.spark.eventLog.enabled=true
kylin.engine.spark-conf.spark.eventLog.dir=hdfs\:///kylin/spark-history
kylin.engine.spark-conf.spark.history.fs.logDirectory=hdfs\:///kylin/spark-history
kylin.engine.spark-conf.spark.hadoop.yarn.timeline-service.enabled=false

# manually upload spark-assembly jar to HDFS and then set this property will avoid repeatedly uploading jar at runtime
#kylin.engine.spark-conf.spark.yarn.jar=hdfs://namenode:8020/kylin/spark/spark-assembly-1.6.3-hadoop2.6.0.jar
#kylin.engine.spark-conf.spark.io.compression.codec=org.apache.spark.io.SnappyCompressionCodec

# uncomment for HDP
#kylin.engine.spark-conf.spark.driver.extraJavaOptions=-Dhdp.version=current
#kylin.engine.spark-conf.spark.yarn.am.extraJavaOptions=-Dhdp.version=current
#kylin.engine.spark-conf.spark.executor.extraJavaOptions=-Dhdp.version=current


### QUERY PUSH DOWN ###

#kylin.query.pushdown.runner-class-name=org.apache.kylin.query.adhoc.PushDownRunnerJdbcImpl

#kylin.query.pushdown.update-enabled=false
#kylin.query.pushdown.jdbc.url=jdbc:hive2://sandbox:10000/default
#kylin.query.pushdown.jdbc.driver=org.apache.hive.jdbc.HiveDriver
#kylin.query.pushdown.jdbc.username=hive
#kylin.query.pushdown.jdbc.password=

#kylin.query.pushdown.jdbc.pool-max-total=8
#kylin.query.pushdown.jdbc.pool-max-idle=8
#kylin.query.pushdown.jdbc.pool-min-idle=0

### TABLE ACL
kylin.query.acl.table-acl-enabled=true
kylin.query.intercepts=org.apache.kylin.rest.security.TableIntercept