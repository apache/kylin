#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Env DEV|QA|PROD
kylin.env=UT
kylin.env.zookeeper-connect-string=localhost:2181


### SERVICE ###


### SOURCE ###


### STORAGE ###

# Working folder in HDFS, make sure user has the right access to the hdfs directory
kylin.env.hdfs-working-dir=/kylin


### JOB ###

# max job retry on error, default 0: no retry
kylin.job.retry=0

# If true, job engine will not assume that hadoop CLI reside on the same server as it self
# you will have to specify kylin.job.remote-cli-hostname, kylin.job.remote-cli-username and kylin.job.remote-cli-password
# It should not be set to "true" unless you're NOT running Kylin.sh on a hadoop client machine
# (Thus kylin instance has to ssh to another real hadoop client machine to execute hive,hadoop commands)
kylin.job.use-remote-cli=false

# Only necessary when kylin.job.use-remote-cli=true
kylin.job.remote-cli-hostname=

kylin.job.remote-cli-port=22

# Only necessary when kylin.job.use-remote-cli=true
kylin.job.remote-cli-username=

# Only necessary when kylin.job.use-remote-cli=true
kylin.job.remote-cli-password=

# Used by test cases to prepare synthetic data for sample cube
kylin.job.remote-cli-working-dir=/tmp/kylin

# Max count of concurrent jobs running
kylin.job.max-concurrent-jobs=10

### Spark conf overwrite
kylin.engine.spark-conf.spark.history.fs.logDirectory=${kylin.env.hdfs-working-dir}/spark-history
kylin.engine.spark-conf.spark.eventLog.dir=${kylin.env.hdfs-working-dir}/spark-history
kylin.engine.spark-conf.spark.hadoop.hive.exec.scratchdir=${kylin.env.hdfs-working-dir}/hive-scratch
kylin.storage.columnar.spark-conf.spark.hadoop.hive.exec.scratchdir=${kylin.env.hdfs-working-dir}/hive-scratch

### CUBE ###


### QUERY ###


### SECURITY ###

# Spring security profile, options: testing, ldap, saml
# with "testing" profile, user can use pre-defined name/pwd like KYLIN/ADMIN to login
kylin.security.profile=testing

# Default roles and admin roles in LDAP, for ldap and saml
kylin.security.acl.default-role=ROLE_ANALYST,ROLE_MODELER
kylin.security.acl.admin-role=ROLE_ADMIN

# LDAP authentication configuration
kylin.security.ldap.connection-server=ldap://ldap_server:389
kylin.security.ldap.connection-username=
kylin.security.ldap.connection-password=

# LDAP user account directory;
kylin.security.ldap.user-search-base=
kylin.security.ldap.user-search-pattern=
kylin.security.ldap.user-group-search-base=

# LDAP service account directory
kylin.security.ldap.service-search-base=
kylin.security.ldap.service-search-pattern=
kylin.security.ldap.service-group-search-base=

# SAML configurations for SSO
# SAML IDP metadata file location
kylin.security.saml.metadata-file=classpath:sso_metadata.xml
kylin.security.saml.metadata-entity-base-url=https://hostname/kylin
kylin.security.saml.context-scheme=https
kylin.security.saml.context-server-name=hostname
kylin.security.saml.context-server-port=443
kylin.security.saml.context-path=/kylin

### MAIL ###
# If true, will send email notification;
#kylin.job.notification-enabled=true
#kylin.job.notification-mail-enable-starttls=true
#kylin.job.notification-mail-host=smtp.office365.com
#kylin.job.notification-mail-port=587
#kylin.job.notification-mail-username=kylin@example.com
#kylin.job.notification-mail-password=mypassword
#kylin.job.notification-mail-sender=kylin@example.com


### OTHER ###

# for tests
kylin.test.bcc.new-key=some-value
kylin.engine.mr.config-override.test1=test1
kylin.engine.mr.config-override.test2=test2
kylin.job.lock=org.apache.kylin.job.lock.MockJobLockDup
kylin.job.lock=org.apache.kylin.job.lock.MockJobLock


kylin.source.provider.9=org.apache.kylin.engine.spark.mockup.CsvSource

kylin.storage.columnar.spark-conf.spark.master=local
kylin.query.engine.sparder-additional-files=../../build/conf/spark-executor-log4j.xml

kylin.source.jdbc.adaptor=org.apache.kylin.sdk.datasource.adaptor.H2Adaptor
kylin.source.jdbc.driver=org.h2.Driver
kylin.source.jdbc.connection-url=jdbc:h2:mem:db
kylin.source.jdbc.user=
kylin.source.jdbc.pass=

kylin.smart.conf.propose-runner-type=in-memory
kylin.swagger.enabled=false
kylin.engine.persist-flattable-enabled=true

kylin.storage.columnar.spark-conf.spark.sql.warehouse.dir=${kylin.env.hdfs-working-dir}/spark-warehouse
kylin.storage.columnar.spark-conf.spark.hadoop.javax.jdo.option.ConnectionURL=jdbc:derby:memory:db;create=true

kylin.engine.spark-conf.spark.master=local[8]
kylin.metadata.random-admin-password.enabled=true
kylin.monitor.enabled=false

kylin.engine.spark-conf.spark.driver.cores=2
kylin.engine.spark-conf.spark.driver.memory=512m
kylin.engine.spark-conf.spark.driver.memoryOverhead=512m
kylin.engine.spark-conf.spark.executor.cores=2
kylin.engine.spark-conf.spark.executor.instances=1
kylin.engine.spark-conf.spark.executor.memory=512m
kylin.engine.spark-conf.spark.executor.memoryOverhead=512m


kylin.storage.columnar.spark-conf.spark.driver.cores=1
kylin.storage.columnar.spark-conf.spark.driver.memory=512m
kylin.storage.columnar.spark-conf.spark.driver.memoryOverhead=512m
kylin.storage.columnar.spark-conf.spark.executor.cores=1
kylin.storage.columnar.spark-conf.spark.executor.instances=1
kylin.storage.columnar.spark-conf.spark.executor.memory=512m
kylin.storage.columnar.spark-conf.spark.executor.memoryOverhead=512m
