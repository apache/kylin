#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

### SERVICE ###

# Kylin server mode, valid value [all, query, job]
kylin.server.mode=all

# Optional information for the owner of kylin platform, it can be your team's email
# Currently it will be attached to each kylin's htable attribute
kylin.storage.hbase.owner-tag=whoami@kylin.apache.org

# List of web servers in use, this enables one web server instance to sync up with other servers.
#kylin.server.cluster-servers=localhost:7070

# Display timezone on UI,format like[GMT+N or GMT-N]
kylin.web.timezone=GMT+8

### SOURCE ###

# Hive client, valid value [cli, beeline]
kylin.source.hive.client=cli
#kylin.source.hive.beeline-params=-n root --hiveconf hive.security.authorization.sqlstd.confwhitelist.append='mapreduce.job.*|dfs.*' -u 'jdbc:hive2://localhost:10000'

### STORAGE ###

# The metadata store in hbase
kylin.metadata.url=kylin_default_instance@hbase

# The storage for final cube file in hbase
kylin.storage.url=hbase

# Working folder in HDFS, make sure user has the right access to the hdfs directory
kylin.env.hdfs-working-dir=/kylin

# HBase Cluster FileSystem, which serving hbase, format as hdfs://hbase-cluster:8020
# Leave empty if hbase running on same cluster with hive and mapreduce
#kylin.storage.hbase.cluster-fs=


kylin.engine.mr.reduce-input-mb=500

### JOB ###

# max job retry on error, default 0: no retry
kylin.job.retry=0

# If true, job engine will not assume that hadoop CLI reside on the same server as it self
# you will have to specify kylin.job.remote-cli-hostname, kylin.job.remote-cli-username and kylin.job.remote-cli-password
# It should not be set to "true" unless you're NOT running Kylin.sh on a hadoop client machine
# (Thus kylin instance has to ssh to another real hadoop client machine to execute hbase,hive,hadoop commands)
kylin.job.use-remote-cli=false

# Only necessary when kylin.job.use-remote-cli=true
kylin.job.remote-cli-hostname=sandbox

kylin.job.remote-cli-username=root

# Only necessary when kylin.job.use-remote-cli=true
kylin.job.remote-cli-password=hadoop

# Used by test cases to prepare synthetic data for sample cube
kylin.job.remote-cli-working-dir=/tmp/kylin

# Max count of concurrent jobs running
kylin.job.max-concurrent-jobs=10

kylin.source.hive.redistribute-flat-table=false

# Time interval to check hadoop job status
kylin.engine.mr.yarn-check-interval-seconds=10

# Hive database name for putting the intermediate flat tables
kylin.source.hive.database-for-flat-table=default

#default compression codec for htable,snappy,lzo,gzip,lz4
kylin.storage.hbase.compression-codec=gzip

# Max reducer number
kylin.engine.mr.max-reducer-number=5

# The percentage of the sampling, default 100%
kylin.job.sampling-percentage=100

# The cut size for hbase region, in GB.
# E.g, for cube whose capacity be marked as "SMALL", split region per 10GB by default
kylin.storage.hbase.region-cut-gb=0.1
kylin.storage.hbase.max-region-count=5

# The hfile size of GB, smaller hfile leading to the converting hfile MR has more reducers and be faster
# set 0 to disable this optimization
kylin.storage.hbase.hfile-size-gb=2

kylin.query.udf.massin=org.apache.kylin.query.udf.MassInUDF
kylin.query.udf.version=org.apache.kylin.query.udf.VersionUDF

# for test
kylin.job.lock=org.apache.kylin.job.lock.MockJobLock
kylin.engine.mr.uhc-reducer-count=1

### CUBE ###

# dictionary forest cut
kylin.dictionary.forest-trie-max-mb=500

# 'auto', 'inmem', 'layer' or 'random' for testing
kylin.cube.algorithm=random

# Enable/disable ACL check for cube query
kylin.query.security-enabled=true

### SECURITY ###

# Spring security profile, options: testing, ldap, saml
# with "testing" profile, user can use pre-defined name/pwd like KYLIN/ADMIN to login
kylin.security.profile=testing

# Default roles and admin roles in LDAP, for ldap and saml
kylin.security.acl.default-role=ROLE_ANALYST,ROLE_MODELER
kylin.security.acl.admin-role=ROLE_ADMIN


### MAIL ###

# If true, will send email notification;
kylin.job.notification-enabled=false

### WEB ###

# Help info, format{name|displayName|link}, optional
kylin.web.help.length=4
kylin.web.help.0=start|Getting Started|
kylin.web.help.1=odbc|ODBC Driver|
kylin.web.help.2=tableau|Tableau Guide|
kylin.web.help.3=onboard|Cube Design Tutorial|


### OTHER ###

# kylin query metrics percentiles intervals default=60, 300, 3600
kylin.server.query-metrics-percentiles-intervals=60, 360, 3600

# Env DEV|QA|PROD
kylin.env=DEV
kylin.source.hive.keep-flat-table=false

### Spark as Engine ###
kylin.engine.spark.env.hadoop-conf-dir=../examples/test_case_data/sandbox
kylin.engine.spark.sanity-check-enabled=false

### Spark conf overwrite for cube engine
kylin.engine.spark-conf.spark.master=yarn
kylin.engine.spark-conf.spark.submit.deployMode=client
kylin.engine.spark-conf.spark.yarn.executor.memoryOverhead=512
kylin.engine.spark-conf.spark.yarn.driver.memoryOverhead=384
kylin.engine.spark-conf.spark.executor.memory=1G
kylin.engine.spark-conf.spark.executor.cores=1
kylin.engine.spark-conf.spark.executor.instances=1
kylin.engine.spark-conf.spark.storage.memoryFraction=0.3
kylin.engine.spark-conf.spark.history.fs.logDirectory=hdfs\:///kylin/spark-history
kylin.engine.spark-conf.spark.eventLog.dir=hdfs\:///kylin/spark-history
#kylin.engine.spark-conf.spark.yarn.queue=default
#kylin.engine.spark-conf.spark.yarn.jar=hdfs://sandbox.hortonworks.com:8020/kylin/spark/spark-assembly-1.6.3-hadoop2.6.0.jar
#kylin.engine.spark-conf.spark.io.compression.codec=org.apache.spark.io.SnappyCompressionCodec
