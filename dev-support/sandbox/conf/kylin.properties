#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

### METADATA | ENV ###
# Env DEV|QA|PROD
kylin.env=DEV

# The metadata store, by default stored in jdbc
kylin.metadata.url=ke_metadata@jdbc,driverClassName=com.mysql.jdbc.Driver,url=jdbc:mysql://mysql:3306/kylin?useSSL=false,createDatabaseIfNotExist=true,username=root,password=root

kylin.source.record-source-usage-enabled=false

### SERVICE ###
# need by DependencyEnvironmentPostProcessor
kylin.server.mode=all

### SOURCE ###


### STORAGE ###

# Working folder in HDFS, make sure user has the right access to the hdfs directory
kylin.env.hdfs-working-dir=/kylin

kylin.env.zookeeper-connect-string=zookeeper:2181

### JOB ###

# max job retry on error, default 0: no retry
kylin.job.retry=0

# If true, job engine will not assume that hadoop CLI reside on the same server as it self
# you will have to specify kylin.job.remote-cli-hostname, kylin.job.remote-cli-username and kylin.job.remote-cli-password
# It should not be set to "true" unless you're NOT running Kylin.sh on a hadoop client machine
# (Thus kylin instance has to ssh to another real hadoop client machine to execute hive,hadoop commands)
kylin.job.use-remote-cli=false

# Only necessary when kylin.job.use-remote-cli=true
kylin.job.remote-cli-hostname=sandbox

kylin.job.remote-cli-port=22

# Only necessary when kylin.job.use-remote-cli=true
kylin.job.remote-cli-username=root

# Only necessary when kylin.job.use-remote-cli=true
kylin.job.remote-cli-password=hadoop

# Used by test cases to prepare synthetic data for sample cube
kylin.job.remote-cli-working-dir=/tmp/kylin

# Max count of concurrent jobs running
kylin.job.max-concurrent-jobs=10


kylin.engine.spark-conf.spark.sql.hive.metastore.version=1.2.2
kylin.engine.spark-conf.spark.sql.hive.metastore.jars=${KYLIN_HOME}/build/spark/hive_1_2_2/*

kylin.engine.spark-conf.spark.driver.memory=512m
kylin.engine.spark-conf.spark.executor.memory=512m
kylin.engine.spark-conf.spark.executor.memoryOverhead=512m
kylin.engine.spark-conf.spark.executor.cores=1
kylin.engine.spark-conf.spark.executor.instances=1


kylin.engine.spark.job-jar=../assembly/target/kylin-assembly-5.0.0-SNAPSHOT-job.jar



### QUERY ###


### SECURITY ###

# Spring security profile, options: testing, ldap, saml
# with "testing" profile, user can use pre-defined name/pwd like KYLIN/ADMIN to login
kylin.security.profile=testing

# Default roles and admin roles in LDAP, for ldap and saml
kylin.security.acl.default-role=ROLE_ANALYST,ROLE_MODELER
kylin.security.acl.admin-role=ROLE_ADMIN

# LDAP authentication configuration
kylin.security.ldap.connection-server=ldap://ldap_server:389
kylin.security.ldap.connection-username=
kylin.security.ldap.connection-password=

# LDAP user account directory;
kylin.security.ldap.user-search-base=
kylin.security.ldap.user-search-pattern=
kylin.security.ldap.user-group-search-base=

# LDAP service account directory
kylin.security.ldap.service-search-base=
kylin.security.ldap.service-search-pattern=
kylin.security.ldap.service-group-search-base=

# SAML configurations for SSO
# SAML IDP metadata file location
kylin.security.saml.metadata-file=classpath:sso_metadata.xml
kylin.security.saml.metadata-entity-base-url=https://hostname/kylin
kylin.security.saml.context-scheme=https
kylin.security.saml.context-server-name=hostname
kylin.security.saml.context-server-port=443
kylin.security.saml.context-path=/kylin

### MAIL ###
# If true, will send email notification;
#kylin.job.notification-enabled=true
#kylin.job.notification-mail-enable-starttls=true
#kylin.job.notification-mail-host=smtp.office365.com
#kylin.job.notification-mail-port=587
#kylin.job.notification-mail-username=kylin@example.com
#kylin.job.notification-mail-password=mypassword
#kylin.job.notification-mail-sender=kylin@example.com


### OTHER ###

kylin.influxdb.address=influxdb:8086
kylin.swagger.enabled=true

# for tests
kylin.test.bcc.new-key=some-value
kylin.engine.mr.config-override.test1=test1
kylin.engine.mr.config-override.test2=test2
kylin.job.lock=org.apache.kylin.job.lock.MockJobLock


kylin.query.engine.sparder-additional-files=../../build/conf/spark-executor-log4j.xml,../../build/conf/spark-appmaster-log4j.xml




#kylin.engine.spark-conf.spark.driver.memory=512m
kylin.storage.columnar.spark-conf.spark.driver.memory=512m
kylin.storage.columnar.spark-conf.spark.executor.memory=512m
kylin.storage.columnar.spark-conf.spark.executor.memoryOverhead=512m
kylin.storage.columnar.spark-conf.spark.executor.extraJavaOptions=-Dhdp.version=current -Dlog4j.configurationFile=spark-executor-log4j.xml -Dlog4j.debug -Dkylin.hdfs.working.dir=${kylin.env.hdfs-working-dir} -Dkap.metadata.identifier=${kylin.metadata.url.identifier} -Dkap.spark.category=sparder -Dkap.spark.project=${job.project} -XX:MaxDirectMemorySize=512M

kylin.storage.columnar.spark-conf.spark.yarn.am.memory=512m
kylin.storage.columnar.spark-conf.spark.executor.cores=1
kylin.storage.columnar.spark-conf.spark.executor.instances=1
kylin.storage.columnar.spark-conf.spark.eventLog.enabled=true
kylin.storage.columnar.spark-conf.spark.history.fs.logDirectory=${kylin.env.hdfs-working-dir}/sparder-history
kylin.storage.columnar.spark-conf.spark.eventLog.dir=${kylin.env.hdfs-working-dir}/sparder-history
kylin.storage.columnar.spark-conf.spark.eventLog.rolling.enabled=true
kylin.storage.columnar.spark-conf.spark.eventLog.rolling.maxFileSize=50m
kylin.storage.columnar.spark-conf.spark.sql.hive.metastore.version=1.2.2
kylin.storage.columnar.spark-conf.spark.sql.hive.metastore.jars=${KYLIN_HOME}/build/spark/hive_1_2_2/*

# ==================== ASYNC QUERY ====================
# sandbox mode should use smaller resources

kylin.query.async-query.spark-conf.spark.driver.memory=512m
kylin.query.async-query.spark-conf.spark.executor.memory=512m
kylin.query.async-query.spark-conf.spark.executor.memoryOverhead=512m
kylin.query.async-query.spark-conf.spark.executor.extraJavaOptions=-Dhdp.version=current -Dlog4j.configurationFile=spark-executor-log4j.xml -Dlog4j.debug -Dkylin.hdfs.working.dir=${kylin.env.hdfs-working-dir} -Dkap.metadata.identifier=${kylin.metadata.url.identifier} -Dkap.spark.category=sparder -Dkap.spark.project=${job.project} -XX:MaxDirectMemorySize=512M

kylin.query.async-query.spark-conf.spark.yarn.am.memory=512m
kylin.query.async-query.spark-conf.spark.executor.cores=1
kylin.query.async-query.spark-conf.spark.executor.instances=1
kylin.query.async-query.spark-conf.spark.eventLog.enabled=true
kylin.query.async-query.spark-conf.spark.history.fs.logDirectory=${kylin.env.hdfs-working-dir}/sparder-history
kylin.query.async-query.spark-conf.spark.eventLog.dir=${kylin.env.hdfs-working-dir}/sparder-history
kylin.query.async-query.spark-conf.spark.eventLog.rolling.enabled=true
kylin.query.async-query.spark-conf.spark.eventLog.rolling.maxFileSize=50m
kylin.query.async-query.spark-conf.spark.sql.hive.metastore.version=1.2.2
kylin.query.async-query.spark-conf.spark.sql.hive.metastore.jars=${KYLIN_HOME}/build/spark/hive_1_2_2/*

kylin.storage.columnar.spark-conf.spark.sql.parquet.columnarReaderBatchSize=1024

### RECOMMENDATION JOB ###
kylin.smart.conf.propose-runner-type=in-memory

#streaming
kylin.streaming.spark-conf.spark.sql.hive.metastore.jars=${KYLIN_HOME}/build/spark/hive_1_2_2/*
kylin.streaming.spark.job-jar=../assembly/target/kylin-assembly-5.0.0-SNAPSHOT-job.jar

kylin.query.escape-default-keyword=true
kylin.monitor.enabled=false
