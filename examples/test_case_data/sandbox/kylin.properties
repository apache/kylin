#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

### SERVICE ###

# Kylin server mode, valid value [all, query, job]
kylin.server.mode=all

# Optional information for the owner of kylin platform, it can be your team's email
# Currently it will be attached to each kylin's htable attribute
kylin.storage.hbase.owner-tag=whoami@kylin.apache.org

# List of web servers in use, this enables one web server instance to sync up with other servers.
kylin.server.cluster-servers=localhost:7070

# Display timezone on UI,format like[GMT+N or GMT-N]
kylin.web.timezone=GMT+8

### SOURCE ###

# Hive client, valid value [cli, beeline]
kylin.source.hive.client=cli
#kylin.source.hive.beeline-params=-n root --hiveconf hive.security.authorization.sqlstd.confwhitelist.append='mapreduce.job.*|dfs.*' -u 'jdbc:hive2://localhost:10000'

### STORAGE ###

# The metadata store in hbase
kylin.metadata.url=kylin_metadata@hbase


# The storage for final cube file in hbase
kylin.storage.url=hbase

# Working folder in HDFS, make sure user has the right access to the hdfs directory
kylin.env.hdfs-working-dir=/kylin

kylin.env.zookeeper-connect-string=sandbox.hortonworks.com

# HBase Cluster FileSystem, which serving hbase, format as hdfs://hbase-cluster:8020
# Leave empty if hbase running on same cluster with hive and mapreduce
#kylin.storage.hbase.cluster-fs=


kylin.engine.mr.reduce-input-mb=500

kylin.engine.mr.uhc-config-override.mapreduce.reduce.memory.mb=500
kylin.engine.mr.uhc-config-override.mapred.reduce.child.java.opts=-Xmx400M


### JOB ###

# max job retry on error, default 0: no retry
kylin.job.retry=0

# If true, job engine will not assume that hadoop CLI reside on the same server as it self
# you will have to specify kylin.job.remote-cli-hostname, kylin.job.remote-cli-username and kylin.job.remote-cli-password
# It should not be set to "true" unless you're NOT running Kylin.sh on a hadoop client machine
# (Thus kylin instance has to ssh to another real hadoop client machine to execute hbase,hive,hadoop commands)
kylin.job.use-remote-cli=false

# Only necessary when kylin.job.use-remote-cli=true
kylin.job.remote-cli-hostname=sandbox

kylin.job.remote-cli-username=root

# Only necessary when kylin.job.use-remote-cli=true
kylin.job.remote-cli-password=hadoop

# Used by test cases to prepare synthetic data for sample cube
kylin.job.remote-cli-working-dir=/tmp/kylin

# Max count of concurrent jobs running
kylin.job.max-concurrent-jobs=10

kylin.source.hive.redistribute-flat-table=false

# Time interval to check hadoop job status
kylin.engine.mr.yarn-check-interval-seconds=10

# Hive database name for putting the intermediate flat tables
kylin.source.hive.database-for-flat-table=default

# Hive flat table storage format, defaults to sequencefile
#kylin.source.hive.flat-table-storage-format=textfile

# Hive flat table field delimiter; used only when kylin.source.hive.flat-table-storage-format is set to textfile; defaults to \u001F (unit separator)
#kylin.source.hive.flat-table-field-delimiter=\\u001F


#default compression codec for htable,snappy,lzo,gzip,lz4
kylin.storage.hbase.compression-codec=gzip

# Max reducer number
kylin.engine.mr.max-reducer-number=5

# The percentage of the sampling, default 100%
kylin.job.sampling-percentage=100

# The cut size for hbase region, in GB.
# E.g, for cube whose capacity be marked as "SMALL", split region per 10GB by default
kylin.storage.hbase.region-cut-gb=0.1
kylin.storage.hbase.max-region-count=5

# The hfile size of GB, smaller hfile leading to the converting hfile MR has more reducers and be faster
# set 0 to disable this optimization
kylin.storage.hbase.hfile-size-gb=2

# for test
kylin.job.lock=org.apache.kylin.job.lock.MockJobLock
kylin.engine.mr.uhc-reducer-count=3

### CUBE ###

# dictionary forest cut
kylin.dictionary.forest-trie-max-mb=500

# 'auto', 'inmem', 'layer' or 'random' for testing
kylin.cube.algorithm=random

# Enable/disable ACL check for cube query
kylin.query.security-enabled=true

### SECURITY ###

# Spring security profile, options: testing, ldap, saml
# with "testing" profile, user can use pre-defined name/pwd like KYLIN/ADMIN to login
kylin.security.profile=testing

# Admin roles in LDAP, for ldap and saml
kylin.security.acl.admin-role=admin


### MAIL ###

# If true, will send email notification;
#kylin.job.notification-enabled=true
#kylin.job.notification-mail-enable-starttls=true
#kylin.job.notification-mail-host=smtp.office365.com
#kylin.job.notification-mail-port=587
#kylin.job.notification-mail-username=kylin@example.com
#kylin.job.notification-mail-password=mypassword
#kylin.job.notification-mail-sender=kylin@example.com

### WEB ###

# Help info, format{name|displayName|link}, optional
kylin.web.help.length=4
kylin.web.help.0=start|Getting Started|http://kylin.apache.org/docs/tutorial/kylin_sample.html
kylin.web.help.1=odbc|ODBC Driver|http://kylin.apache.org/docs/tutorial/odbc.html
kylin.web.help.2=tableau|Tableau Guide|http://kylin.apache.org/docs/tutorial/tableau_91.html
kylin.web.help.3=onboard|Cube Design Tutorial|http://kylin.apache.org/docs/howto/howto_optimize_cubes.html

#allow user to export query result
kylin.web.export-allow-admin=true
kylin.web.export-allow-other=true

# Hide measures in measure list of cube designer, separate by comma
kylin.web.hide-measures=RAW

### OTHER ###

# kylin query metrics percentiles intervals default=60, 300, 3600
kylin.server.query-metrics-percentiles-intervals=60, 360, 3600

# Env DEV|QA|PROD
kylin.env=DEV
kylin.source.hive.keep-flat-table=false


# Estimate the RDD partition numbers, the test cubes have a couple memory-hungry measure so the estimation is wild
kylin.engine.spark.rdd-partition-cut-mb=100

### Spark conf overwrite for cube engine
kylin.engine.spark-conf.spark.yarn.submit.file.replication=1
kylin.engine.spark-conf.spark.master=yarn
#kylin.engine.spark-conf.spark.submit.deployMode=cluster
kylin.engine.spark-conf.spark.yarn.executor.memoryOverhead=384
kylin.engine.spark-conf.spark.yarn.driver.memoryOverhead=256
kylin.engine.spark-conf.spark.executor.memory=768M
kylin.engine.spark-conf.spark.executor.cores=1
kylin.engine.spark-conf.spark.executor.instances=1
kylin.engine.spark-conf.spark.eventLog.enabled=true
kylin.engine.spark-conf.spark.history.fs.logDirectory=hdfs\:///spark-history
kylin.engine.spark-conf.spark.eventLog.dir=hdfs\:///spark-history
#kylin.engine.spark-conf.spark.yarn.archive=hdfs://sandbox.hortonworks.com:8020/kylin/spark/spark-libs.jar
kylin.engine.spark-conf.spark.driver.extraJavaOptions=-Dhdp.version=current
kylin.engine.spark-conf.spark.yarn.am.extraJavaOptions=-Dhdp.version=current
kylin.engine.spark-conf.spark.executor.extraJavaOptions=-Dhdp.version=current
kylin.engine.spark-conf.spark.hadoop.yarn.timeline-service.enabled=false

### Spark conf for specific job
kylin.engine.spark-conf-mergedict.spark.executor.memory=1G
kylin.engine.spark-conf-mergedict.spark.memory.fraction=0.2

### QUERY PUSH DOWN  ###
#kylin.query.pushdown.runner-class-name=org.apache.kylin.query.adhoc.PushDownRunnerJdbcImpl

#kylin.query.pushdown.jdbc.url=jdbc:hive2://sandbox:10000/default
#kylin.query.pushdown.jdbc.driver=org.apache.hive.jdbc.HiveDriver
#kylin.query.pushdown.jdbc.username=hive
#kylin.query.pushdown.jdbc.password=

#kylin.query.pushdown.jdbc.pool-max-total=8
#kylin.query.pushdown.jdbc.pool-max-idle=8
#kylin.query.pushdown.jdbc.pool-min-idle=0

kylin.query.transformers=org.apache.kylin.query.util.DefaultQueryTransformer
