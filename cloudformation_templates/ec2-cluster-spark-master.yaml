AWSTemplateFormatVersion: 2010-09-09
Description: Create SparkMaster nodes for ec2 instances and deploy related services, hadoop/spark/zookeeper/hive/jdk/kylin4
Parameters:
  # Must passed Parameters
  InstanceProfileId:
    Type: String
    Description: Must be created at pre-step
  SubnetId:
    Type: String
  SecurityGroupId:
    Type: String
  AssociatedPublicIp:
    Type: String
    Default: true
    AllowedValues:
      - true
      - false
  EMREc2KeyName:
    Type: String
  DbHost:
    Type: String
    Description: the host of RDS instance
  DbUser:
    Type: String
    Description: the user to access RDS instance
  DbPassword:
    Type: String
    Description: the password to access RDS instance
  DbPort:
    Type: String
    Description: the port to access RDS instance
    Default: 3306

  Ec2Mode:
    Type: String
    Default: test
    AllowedValues:
      - test
      - product
    Description: set the flag for Mode, if not test use product's configuration

#   Optional Parameters
  LocalCacheSoftAffinity:
    Type: String
    Default: false
    AllowedValues:
      - true
      - false
  BucketFullPath:
    Type: String
  BucketPath:
    Type: String
    Description: Url without prefix s3:/
  SparkMasterScriptFileName:
    Type: String
    Default: prepare-ec2-env-for-spark-master.sh
  InstanceType:
    Description: EC2 instance type
    Type: String
    ConstraintDescription: must be a valid EC2 instance type.
    Default: m5.2xlarge
    AllowedValues:
      - m5.xlarge
      - m5.2xlarge
      - m5.4xlarge
  InstanceTypeForTest:
    Description: EC2 instance type
    Type: String
    ConstraintDescription: must be a valid EC2 instance type.
    Default: m5.2xlarge
    AllowedValues:
      - m5.2xlarge
  Ec2VolumnTypeForSparkMasterNode:
    Type: String
    Default: gp2
    AllowedValues:
      - gp2
      - gp3
      - io1
      - io2
      - sc1
      - st1
      - standard
  Ec2VolumeSizeForSparkMasterNode:
    Type: Number
    Default: 30
    MinValue: 30
    MaxValue: 100

  Ec2VolumnTypeForSparkMasterNodeForTest:
    Type: String
    Default: gp2
    AllowedValues:
      - gp2

  Ec2VolumeSizeForSparkMasterNodeForTest:
    Type: Number
    Default: 30
    MinValue: 30
    MaxValue: 30


Mappings:
  AWSRegionArch2AMI:
    cn-north-1:
      HVMebs: ami-00ac27054b887ff5c
    cn-northwest-1:
      HVMebs: ami-0135cb179d33fbe3e

Conditions:
  NotNullSubnetId:
    !Not [!Equals [!Ref SubnetId, ""]]
  NotNullEc2KeyName:
    !Not [!Equals [!Ref EMREc2KeyName, ""]]
  IsProductMode: !Equals [!Ref Ec2Mode, "product"]
  ValidConfigurationForEc2: !And
    - !Condition NotNullSubnetId
    - !Condition NotNullEc2KeyName
  IsAssociatedPublicIp: !Equals [!Ref AssociatedPublicIp, "true"]

Resources:
  Ec2InstanceOfSparkMaster:
    Type: AWS::EC2::Instance
    DeletionPolicy: Delete
    Condition: ValidConfigurationForEc2
    Properties:
      ImageId: !FindInMap
        - AWSRegionArch2AMI
        - !Ref 'AWS::Region'
        - HVMebs
      Tags:
        - Key: Project
          Value: Kylin4
        - Key: Name
          Value: Spark Master Node for kylin4
      InstanceType:
        !If
          - IsProductMode
          - !Ref InstanceType
          - !Ref InstanceTypeForTest
      IamInstanceProfile: !Ref InstanceProfileId
      NetworkInterfaces:
        - DeviceIndex: 0
          Description: Auto create for SparkMaster node in benchmark
          DeleteOnTermination: true
          AssociatePublicIpAddress: !Ref AssociatedPublicIp
          SubnetId: !Ref SubnetId
          GroupSet:
            - !Ref SecurityGroupId
      BlockDeviceMappings:
        - !If
          - IsProductMode
          - DeviceName: /dev/xvda
            Ebs:
              VolumeSize: !Ref Ec2VolumeSizeForSparkMasterNode
              VolumeType: !Ref Ec2VolumnTypeForSparkMasterNode
              DeleteOnTermination: true
          - DeviceName: /dev/xvda
            Ebs:
              VolumeSize: !Ref Ec2VolumeSizeForSparkMasterNodeForTest
              VolumeType: !Ref Ec2VolumnTypeForSparkMasterNodeForTest
              DeleteOnTermination: true
      KeyName: !Ref EMREc2KeyName
      UserData:
        Fn::Base64:
          Fn::Sub:
            - |
              #!/bin/bash -xe
              cd /home/ec2-user
              aws s3 cp ${PrivateBucketFullPath}/scripts/${PrivateSparkMasterScriptFileName} . --region ${PrivateRegion}
              bash ${PrivateSparkMasterScriptFileName} --bucket-url ${PrivateBucketPath} --region ${PrivateRegion} --local-soft ${PrivateLocalCacheSoftAffinity} --db-port ${PrivateDbPort} --db-host ${PrivateDbHost} --db-user ${PrivateDbUser} --db-password ${PrivateDbPassword}
              echo " Spark Master is ready ..."
            - PrivateBucketFullPath: !Ref BucketFullPath
              PrivateSparkMasterScriptFileName: !Ref SparkMasterScriptFileName
              PrivateBucketPath: !Ref BucketPath
              PrivateRegion: !Ref AWS::Region
              PrivateLocalCacheSoftAffinity: !Ref LocalCacheSoftAffinity
              PrivateDbPort: !Ref DbPort
              PrivateDbHost: !Ref DbHost
              PrivateDbUser: !Ref DbUser
              PrivateDbPassword: !Ref DbPassword

Outputs:
  IdOfInstance:
    Description: the id of SparkMaster Node Instance
    Value: !Ref Ec2InstanceOfSparkMaster
  SparkMasterNodeHost:
    Description: SparkMaster host is same as private IP
    Value: !GetAtt Ec2InstanceOfSparkMaster.PrivateIp
  SparkMasterEc2InstancePrivateIp:
    Description: SparkMaster Instance Private IP
    Value: !GetAtt Ec2InstanceOfSparkMaster.PrivateIp
  SparkMasterEc2InstancePublicIp:
    Description: SparkMaster Instance Public IP to acess
    Value: !GetAtt Ec2InstanceOfSparkMaster.PublicIp
    Condition: IsAssociatedPublicIp
  SparkMasterEc2InstanceProfileId:
    Value: !Ref InstanceProfileId
  SparkMasterSubnetIdDependsOnDNode:
    Value: !Ref SubnetId
  SparkMasterSecurityGroupIdDependsOnDNode:
    Value: !Ref SecurityGroupId
