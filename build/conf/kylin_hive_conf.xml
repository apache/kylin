<?xml version="1.0"?>
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>2</value>
        <description>Block replication</description>
    </property>

    <property>
        <name>dfs.block.size</name>
        <value>10485760</value>
        <description>Want more mappers for in-mem cubing, thus smaller the DFS block size</description>
    </property>

    <property>
        <name>hive.exec.compress.output</name>
        <value>true</value>
        <description>enable compress</description>
    </property>

    <property>
        <name>hive.auto.convert.join.noconditionaltask</name>
        <value>true</value>
        <description>enable map-side join</description>
    </property>

    <property>
        <name>hive.auto.convert.join.noconditionaltask.size</name>
        <value>300000000</value>
        <description>enable map-side join</description>
    </property>

    <property>
        <name>mapreduce.map.output.compress.codec</name>
        <value>org.apache.hadoop.io.compress.SnappyCodec</value>
        <description></description>
    </property>
    <property>
        <name>mapreduce.output.fileoutputformat.compress.codec</name>
        <value>org.apache.hadoop.io.compress.SnappyCodec</value>
        <description></description>
    </property>
    
    <property>
        <name>hive.merge.mapfiles</name>
        <value>true</value>
        <description>Enable hive file merge on mapper only job</description>
    </property>
    <property>
        <name>hive.merge.mapredfiles</name>
        <value>true</value>
        <description>Enable hive file merge on map-reduce job</description>
    </property>
    <property>
        <name>mapred.output.compression.type</name>
        <value>BLOCK</value>
        <description>The compression type to use for job outputs</description>
    </property>
    <property>
        <name>hive.merge.size.per.task</name>
        <value>256000000</value>
        <description>Size for the merged file</description>
    </property>

    <property>
        <name>hive.support.concurrency</name>
        <value>false</value>
        <description>Hive concurrency lock</description>
    </property>

    <property>
        <name>mapreduce.job.split.metainfo.maxsize</name>
        <value>-1</value>
        <description>The maximum permissible size of the split metainfo file.
            The JobTracker won't attempt to read split metainfo files bigger than
            the configured value. No limits if set to -1.
        </description>
    </property>
</configuration>